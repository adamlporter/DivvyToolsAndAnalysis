{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One challenge with the DIVVY data is that it comes in several different forms.\n",
    "I've downloaded and unzipped all the data from 2017 to 2021.\n",
    "The following shows that there are 9 different "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "workDir = '/home/alp/Google Drive/Python/DataSets/Data_Divvy/CVS_archive'\n",
    "\n",
    "file_names = sorted(glob.glob(workDir+'Divvy*.csv'))\n",
    "\n",
    "cols = []\n",
    "line = ''\n",
    "\n",
    "for file in file_names:\n",
    "    with open(file) as f:\n",
    "        newln = f.readline()\n",
    "        if newln != line:\n",
    "            cols.append((file.replace(workDir,''),newln))\n",
    "            line = newln\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "blech - this is still hard to read. Let's sort the list by the variable lists and then find the list of unique variable names, so we can compare them more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_cols = []\n",
    "cStr = ''\n",
    "cols.sort(key = lambda x: x[1])\n",
    "for c in cols:\n",
    "    if c[1] != cStr:\n",
    "        c_cols.append(c)\n",
    "        cStr = c[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 [('202004-divvy-tripdata.csv', 'ride_id,rideable_type,started_at,ended_at,start_station_name,start_station_id,end_station_name,end_station_id,start_lat,start_lng,end_lat,end_lng,member_casual\\n'), ('Divvy_Trips_2017_Q1.csv', '\"trip_id\",\"start_time\",\"end_time\",\"bikeid\",\"tripduration\",\"from_station_id\",\"from_station_name\",\"to_station_id\",\"to_station_name\",\"usertype\",\"gender\",\"birthyear\"\\n'), ('Divvy_Trips_2017_Q4.csv', 'trip_id,start_time,end_time,bikeid,tripduration,from_station_id,from_station_name,to_station_id,to_station_name,usertype,gender,birthyear\\n'), ('Divvy_Trips_2018_Q1.csv', '01 - Rental Details Rental ID,01 - Rental Details Local Start Time,01 - Rental Details Local End Time,01 - Rental Details Bike ID,01 - Rental Details Duration In Seconds Uncapped,03 - Rental Start Station ID,03 - Rental Start Station Name,02 - Rental End Station ID,02 - Rental End Station Name,User Type,Member Gender,05 - Member Details Member Birthday Year\\n')]\n"
     ]
    }
   ],
   "source": [
    "c_cols.sort(key = lambda x: x[0])\n",
    "print(len(c_cols),c_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so while the columns are set up with different names, the data from 2017-2020Q1 all uses the same number and arrangmeent of columns:\n",
    "1. trip_id\n",
    "1. start_time\n",
    "1. end_time\n",
    "1. bikeid\n",
    "1. tripduration\n",
    "1. from_station_id\n",
    "1. from_station_name\n",
    "1. to_station_id\n",
    "1. to_station_name\n",
    "1. usertype\n",
    "1. gender\n",
    "1. birthyear\n",
    "\n",
    "Before 2020_04, the data is saved in quartly chunks, using a \"YYYYMM-divvy-tripdata.csv\" columns are as follows\n",
    "1. ride_id\n",
    "1. rideable_type\n",
    "1. started_at\n",
    "1. ended_at\n",
    "1. start_station_name\n",
    "1. start_station_id\n",
    "1. end_station_name\n",
    "1. end_station_id\n",
    "1. start_lat\n",
    "1. start_lng\n",
    "1. end_lat\n",
    "1. end_lng\n",
    "1. member_casual\n",
    "\n",
    "For my purposes, the most important data that is missing from pre-2020 data is lat/long data for the stations. It's also annoying that it uses a file naming convention. Let's process all the quarterly data to add the lat/long data and save it as monthly JSON files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter App Token\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sodapy import Socrata\n",
    "\n",
    "#https://data.cityofchicago.org/Transportation/Divvy-Bicycle-Stations/bbyy-e7gq/data\n",
    "\n",
    " \n",
    "print('Enter App Token')\n",
    "appToken = input()\n",
    "\n",
    "client=Socrata('data.cityofchicago.org',appToken)\n",
    "results=client.get('bbyy-e7gq',limit=5000,content_type= 'json')\n",
    "stations = pd.DataFrame.from_dict(results)\n",
    "\n",
    "#url = 'https://data.cityofchicago.org/resource/bbyy-e7gq.json?$$app_token=appToken$limit=10000'\n",
    "#stations = pd.read_json(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1369 entries, 0 to 1368\n",
      "Data columns (total 13 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   id                           1369 non-null   object\n",
      " 1   station_name                 1369 non-null   object\n",
      " 2   total_docks                  1369 non-null   object\n",
      " 3   docks_in_service             1369 non-null   object\n",
      " 4   status                       1369 non-null   object\n",
      " 5   latitude                     1369 non-null   object\n",
      " 6   longitude                    1369 non-null   object\n",
      " 7   location                     1369 non-null   object\n",
      " 8   :@computed_region_awaf_s7ux  1355 non-null   object\n",
      " 9   :@computed_region_6mkv_f3dw  1369 non-null   object\n",
      " 10  :@computed_region_vrxf_vc4k  1355 non-null   object\n",
      " 11  :@computed_region_bdys_3d7i  1355 non-null   object\n",
      " 12  :@computed_region_43wa_7qmu  1355 non-null   object\n",
      "dtypes: object(13)\n",
      "memory usage: 139.2+ KB\n"
     ]
    }
   ],
   "source": [
    "stations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>station_name</th>\n",
       "      <th>total_docks</th>\n",
       "      <th>docks_in_service</th>\n",
       "      <th>status</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location</th>\n",
       "      <th>:@computed_region_awaf_s7ux</th>\n",
       "      <th>:@computed_region_6mkv_f3dw</th>\n",
       "      <th>:@computed_region_vrxf_vc4k</th>\n",
       "      <th>:@computed_region_bdys_3d7i</th>\n",
       "      <th>:@computed_region_43wa_7qmu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Buckingham Fountain (Temp)</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>In Service</td>\n",
       "      <td>41.869620747</td>\n",
       "      <td>-87.623981237</td>\n",
       "      <td>{'latitude': '41.86962074748123', 'longitude':...</td>\n",
       "      <td>48</td>\n",
       "      <td>14913</td>\n",
       "      <td>38</td>\n",
       "      <td>368</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Shedd Aquarium</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>In Service</td>\n",
       "      <td>41.867225957</td>\n",
       "      <td>-87.61535539</td>\n",
       "      <td>{'latitude': '41.86722595682', 'longitude': '-...</td>\n",
       "      <td>48</td>\n",
       "      <td>14913</td>\n",
       "      <td>34</td>\n",
       "      <td>374</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Burnham Harbor</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>In Service</td>\n",
       "      <td>41.857411787</td>\n",
       "      <td>-87.613791525</td>\n",
       "      <td>{'latitude': '41.85741178707404', 'longitude':...</td>\n",
       "      <td>48</td>\n",
       "      <td>21194</td>\n",
       "      <td>34</td>\n",
       "      <td>374</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>State St &amp; Harrison St</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>In Service</td>\n",
       "      <td>41.874053</td>\n",
       "      <td>-87.627716</td>\n",
       "      <td>{'latitude': '41.874053', 'longitude': '-87.62...</td>\n",
       "      <td>48</td>\n",
       "      <td>14913</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Dusable Harbor</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>In Service</td>\n",
       "      <td>41.886976</td>\n",
       "      <td>-87.612813</td>\n",
       "      <td>{'latitude': '41.886976', 'longitude': '-87.61...</td>\n",
       "      <td>22</td>\n",
       "      <td>21182</td>\n",
       "      <td>38</td>\n",
       "      <td>159</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                station_name total_docks docks_in_service      status  \\\n",
       "0  2  Buckingham Fountain (Temp)          39               39  In Service   \n",
       "1  3              Shedd Aquarium          55               55  In Service   \n",
       "2  4              Burnham Harbor          23               23  In Service   \n",
       "3  5      State St & Harrison St          23               23  In Service   \n",
       "4  6              Dusable Harbor          39               39  In Service   \n",
       "\n",
       "       latitude      longitude  \\\n",
       "0  41.869620747  -87.623981237   \n",
       "1  41.867225957   -87.61535539   \n",
       "2  41.857411787  -87.613791525   \n",
       "3     41.874053     -87.627716   \n",
       "4     41.886976     -87.612813   \n",
       "\n",
       "                                            location  \\\n",
       "0  {'latitude': '41.86962074748123', 'longitude':...   \n",
       "1  {'latitude': '41.86722595682', 'longitude': '-...   \n",
       "2  {'latitude': '41.85741178707404', 'longitude':...   \n",
       "3  {'latitude': '41.874053', 'longitude': '-87.62...   \n",
       "4  {'latitude': '41.886976', 'longitude': '-87.61...   \n",
       "\n",
       "  :@computed_region_awaf_s7ux :@computed_region_6mkv_f3dw  \\\n",
       "0                          48                       14913   \n",
       "1                          48                       14913   \n",
       "2                          48                       21194   \n",
       "3                          48                       14913   \n",
       "4                          22                       21182   \n",
       "\n",
       "  :@computed_region_vrxf_vc4k :@computed_region_bdys_3d7i  \\\n",
       "0                          38                         368   \n",
       "1                          34                         374   \n",
       "2                          34                         374   \n",
       "3                          38                          12   \n",
       "4                          38                         159   \n",
       "\n",
       "  :@computed_region_43wa_7qmu  \n",
       "0                          10  \n",
       "1                          10  \n",
       "2                          10  \n",
       "3                          10  \n",
       "4                          36  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1369 entries, 0 to 1368\n",
      "Data columns (total 13 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   id                           1369 non-null   int64  \n",
      " 1   station_name                 1369 non-null   object \n",
      " 2   total_docks                  1369 non-null   object \n",
      " 3   docks_in_service             1369 non-null   object \n",
      " 4   status                       1369 non-null   object \n",
      " 5   latitude                     1369 non-null   float64\n",
      " 6   longitude                    1369 non-null   float64\n",
      " 7   location                     1369 non-null   object \n",
      " 8   :@computed_region_awaf_s7ux  1355 non-null   object \n",
      " 9   :@computed_region_6mkv_f3dw  1369 non-null   object \n",
      " 10  :@computed_region_vrxf_vc4k  1355 non-null   object \n",
      " 11  :@computed_region_bdys_3d7i  1355 non-null   object \n",
      " 12  :@computed_region_43wa_7qmu  1355 non-null   object \n",
      "dtypes: float64(2), int64(1), object(10)\n",
      "memory usage: 139.2+ KB\n"
     ]
    }
   ],
   "source": [
    "stations['id'] = pd.to_numeric(stations['id'])\n",
    "stations['latitude'] = pd.to_numeric(stations['latitude'])\n",
    "stations['longitude'] = pd.to_numeric(stations['longitude'])\n",
    "stations.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processFile(file,stations):\n",
    "# read the CSV file of trip data from the provided file name,\n",
    "# parsing the two date-time columns as dates,\n",
    "# renaming all columns to standard names, \n",
    "# merge it with the station data. The first merge adds lat/long for 'from station'; the second adds lat/long for the 'to station'\n",
    "# the merge uses the station ID as the item to match on\n",
    "# rename the columns to match those of the post-April 2020 files\n",
    "    trip_data = pd.read_csv(file,parse_dates=[1,2])\n",
    "    trip_data.columns=['trip_id','start_time','end_time','bikeid','tripduration',\n",
    "        'from_station_id','from_station_name','to_station_id','to_station_name',\n",
    "        'usertype','gender','birthyear']\n",
    "    trip_data = pd.merge(trip_data,stations[['id','latitude','longitude']],'left', left_on = 'from_station_id',right_on = 'id')\n",
    "    trip_data = pd.merge(trip_data,stations[['id','latitude','longitude']],'left',left_on = 'to_station_id',right_on = 'id')\n",
    "    trip_data = trip_data.drop(columns = ['id_x','id_y'])\n",
    "    trip_data = trip_data.rename(columns={'latitude_x':'start_lat','longitude_x':'start_lng', 'latitude_y':'end_lat','longitude_y':'end_lng'})\n",
    "\n",
    "    # create grouby frames based on the month\n",
    "    #months = trip_data.groupby(trip_data.start_time.dt.month)\n",
    "    months = trip_data.groupby(pd.Grouper(key = 'start_time', freq='MS'))\n",
    "\n",
    "    workDir = '/home/alp/Google Drive/Python/DataSets/Data_Divvy/'\n",
    "    fn = file.replace(workDir,'')\n",
    "    \n",
    "    for key, gp in months:\n",
    "        fn = key.strftime('%Y') + key.strftime('%m')\n",
    "        saveFile = workDir + 'monthly/' + fn +'-divvy-tripdata.json'\n",
    "        gp.to_json(saveFile,orient='index')\n",
    "        print(saveFile)\n",
    "\n",
    "#    file_dates = trip_data['start_time'].dt.strftime(\"%Y%m\").unique().tolist()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there's something glitchy the data, I had to feed the data files into the procedure one-by-one.\n",
    "2017 Q1-Q3 had problems.\n",
    "2020 Q1 had a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processFile(file_names[1],stations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look a them and get them read correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileN = file_names[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = pd.read_csv(fileN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>tripduration</th>\n",
       "      <th>from_station_id</th>\n",
       "      <th>from_station_name</th>\n",
       "      <th>to_station_id</th>\n",
       "      <th>to_station_name</th>\n",
       "      <th>usertype</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13518905</td>\n",
       "      <td>3/31/2017 23:59:07</td>\n",
       "      <td>4/1/2017 00:13:24</td>\n",
       "      <td>5292</td>\n",
       "      <td>857</td>\n",
       "      <td>66</td>\n",
       "      <td>Clinton St &amp; Lake St</td>\n",
       "      <td>171</td>\n",
       "      <td>May St &amp; Cullerton St</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>1989.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13518904</td>\n",
       "      <td>3/31/2017 23:56:25</td>\n",
       "      <td>4/1/2017 00:00:21</td>\n",
       "      <td>4408</td>\n",
       "      <td>236</td>\n",
       "      <td>199</td>\n",
       "      <td>Wabash Ave &amp; Grand Ave</td>\n",
       "      <td>26</td>\n",
       "      <td>McClurg Ct &amp; Illinois St</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>1990.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13518903</td>\n",
       "      <td>3/31/2017 23:55:33</td>\n",
       "      <td>4/1/2017 00:01:21</td>\n",
       "      <td>696</td>\n",
       "      <td>348</td>\n",
       "      <td>520</td>\n",
       "      <td>Greenview Ave &amp; Jarvis Ave</td>\n",
       "      <td>432</td>\n",
       "      <td>Clark St &amp; Lunt Ave</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Female</td>\n",
       "      <td>1979.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13518902</td>\n",
       "      <td>3/31/2017 23:54:46</td>\n",
       "      <td>3/31/2017 23:59:34</td>\n",
       "      <td>4915</td>\n",
       "      <td>288</td>\n",
       "      <td>110</td>\n",
       "      <td>Dearborn St &amp; Erie St</td>\n",
       "      <td>142</td>\n",
       "      <td>McClurg Ct &amp; Erie St</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>1985.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13518901</td>\n",
       "      <td>3/31/2017 23:53:33</td>\n",
       "      <td>4/1/2017 00:00:28</td>\n",
       "      <td>4247</td>\n",
       "      <td>415</td>\n",
       "      <td>327</td>\n",
       "      <td>Sheffield Ave &amp; Webster Ave</td>\n",
       "      <td>331</td>\n",
       "      <td>Halsted St &amp; Blackhawk St (*)</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Female</td>\n",
       "      <td>1989.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    trip_id          start_time            end_time  bikeid  tripduration  \\\n",
       "0  13518905  3/31/2017 23:59:07   4/1/2017 00:13:24    5292           857   \n",
       "1  13518904  3/31/2017 23:56:25   4/1/2017 00:00:21    4408           236   \n",
       "2  13518903  3/31/2017 23:55:33   4/1/2017 00:01:21     696           348   \n",
       "3  13518902  3/31/2017 23:54:46  3/31/2017 23:59:34    4915           288   \n",
       "4  13518901  3/31/2017 23:53:33   4/1/2017 00:00:28    4247           415   \n",
       "\n",
       "   from_station_id            from_station_name  to_station_id  \\\n",
       "0               66         Clinton St & Lake St            171   \n",
       "1              199       Wabash Ave & Grand Ave             26   \n",
       "2              520   Greenview Ave & Jarvis Ave            432   \n",
       "3              110        Dearborn St & Erie St            142   \n",
       "4              327  Sheffield Ave & Webster Ave            331   \n",
       "\n",
       "                 to_station_name    usertype  gender  birthyear  \n",
       "0          May St & Cullerton St  Subscriber    Male     1989.0  \n",
       "1       McClurg Ct & Illinois St  Subscriber    Male     1990.0  \n",
       "2            Clark St & Lunt Ave  Subscriber  Female     1979.0  \n",
       "3           McClurg Ct & Erie St  Subscriber    Male     1985.0  \n",
       "4  Halsted St & Blackhawk St (*)  Subscriber  Female     1989.0  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, the problem is the time columns (1,2) are using slashe, not dashes, do the date parser is hanging.\n",
    "We'll adjust these manually for each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileN = file_names[2]\n",
    "td = pd.read_csv(fileN)\n",
    "\n",
    "td['start_time'] = pd.to_datetime(td['start_time'],format = '%m/%d/%Y %H:%M:%S')\n",
    "td['end_time'] = pd.to_datetime(td['end_time'],format = '%m/%d/%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alp/Google Drive/Python/DataSets/Data_Divvy/monthly/201707-divvy-tripdata.json\n",
      "/home/alp/Google Drive/Python/DataSets/Data_Divvy/monthly/201708-divvy-tripdata.json\n",
      "/home/alp/Google Drive/Python/DataSets/Data_Divvy/monthly/201709-divvy-tripdata.json\n"
     ]
    }
   ],
   "source": [
    "trip_data = td\n",
    "trip_data.columns=['trip_id','start_time','end_time','bikeid','tripduration',\n",
    "    'from_station_id','from_station_name','to_station_id','to_station_name',\n",
    "    'usertype','gender','birthyear']\n",
    "trip_data = pd.merge(trip_data,stations[['id','latitude','longitude']],'left', left_on = 'from_station_id',right_on = 'id')\n",
    "trip_data = pd.merge(trip_data,stations[['id','latitude','longitude']],'left',left_on = 'to_station_id',right_on = 'id')\n",
    "trip_data = trip_data.drop(columns = ['id_x','id_y'])\n",
    "trip_data = trip_data.rename(columns={'latitude_x':'start_lat','longitude_x':'start_lng', 'latitude_y':'end_lat','longitude_y':'end_lng'})\n",
    "\n",
    "# create grouby frames based on the month\n",
    "#months = trip_data.groupby(trip_data.start_time.dt.month)\n",
    "months = trip_data.groupby(pd.Grouper(key = 'start_time', freq='MS'))\n",
    "\n",
    "workDir = '/home/alp/Google Drive/Python/DataSets/Data_Divvy/'\n",
    "\n",
    "for key, gp in months:\n",
    "    fn = key.strftime('%Y') + key.strftime('%m')\n",
    "    saveFile = workDir + 'monthly/' + fn +'-divvy-tripdata.json'\n",
    "    gp.to_json(saveFile,orient='index')\n",
    "    print(saveFile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at 2020 Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 426887 entries, 0 to 426886\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   ride_id             426887 non-null  object        \n",
      " 1   rideable_type       426887 non-null  object        \n",
      " 2   started_at          426887 non-null  datetime64[ns]\n",
      " 3   ended_at            426887 non-null  object        \n",
      " 4   start_station_name  426887 non-null  object        \n",
      " 5   start_station_id    426887 non-null  int64         \n",
      " 6   end_station_name    426886 non-null  object        \n",
      " 7   end_station_id      426886 non-null  float64       \n",
      " 8   start_lat           426887 non-null  float64       \n",
      " 9   start_lng           426887 non-null  float64       \n",
      " 10  end_lat             426886 non-null  float64       \n",
      " 11  end_lng             426886 non-null  float64       \n",
      " 12  member_casual       426887 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(5), int64(1), object(6)\n",
      "memory usage: 42.3+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "workDir = '/home/alp/Google Drive/Python/DataSets/Data_Divvy/'\n",
    "fileN = 'Divvy_Trips_2020_Q1.csv'\n",
    "td = pd.read_csv(workDir + fileN,parse_dates=[1,2])\n",
    "td.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this file is using the 2020 new column names, including the new 'ridable_type' and the 'member_casual'\n",
    "So we need to read it again with the proper cols identified as dates\n",
    "Since it's alreayd got lat/long data, we can then just break it into months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alp/Google Drive/Python/DataSets/Data_Divvy/202001-divvy-tripdata.json\n",
      "/home/alp/Google Drive/Python/DataSets/Data_Divvy/202002-divvy-tripdata.json\n",
      "/home/alp/Google Drive/Python/DataSets/Data_Divvy/202003-divvy-tripdata.json\n"
     ]
    }
   ],
   "source": [
    "fileN = 'Divvy_Trips_2020_Q1.csv'\n",
    "td = pd.read_csv(workDir + fileN,parse_dates=[2,3])\n",
    "\n",
    "trip_data = td\n",
    "\n",
    "months = trip_data.groupby(pd.Grouper(key = 'started_at', freq='MS'))\n",
    "\n",
    "workDir = '/home/alp/Google Drive/Python/DataSets/Data_Divvy/'\n",
    "\n",
    "for key, gp in months:\n",
    "    fn = key.strftime('%Y') + key.strftime('%m')\n",
    "    saveFile = workDir + fn +'-divvy-tripdata.json'\n",
    "    gp.to_json(saveFile,orient='index')\n",
    "    print(saveFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    143884\n",
       "2    139585\n",
       "3    143418\n",
       "Name: started_at, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DatetimeIndex(td['started_at']).month.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 426887 entries, 0 to 426886\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   ride_id             426887 non-null  object        \n",
      " 1   rideable_type       426887 non-null  object        \n",
      " 2   started_at          426887 non-null  datetime64[ns]\n",
      " 3   ended_at            426887 non-null  datetime64[ns]\n",
      " 4   start_station_name  426887 non-null  object        \n",
      " 5   start_station_id    426887 non-null  int64         \n",
      " 6   end_station_name    426886 non-null  object        \n",
      " 7   end_station_id      426886 non-null  float64       \n",
      " 8   start_lat           426887 non-null  float64       \n",
      " 9   start_lng           426887 non-null  float64       \n",
      " 10  end_lat             426886 non-null  float64       \n",
      " 11  end_lng             426886 non-null  float64       \n",
      " 12  member_casual       426887 non-null  object        \n",
      "dtypes: datetime64[ns](2), float64(5), int64(1), object(5)\n",
      "memory usage: 42.3+ MB\n"
     ]
    }
   ],
   "source": [
    "td.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84776 entries, 0 to 84775\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   ride_id             84776 non-null  object        \n",
      " 1   rideable_type       84776 non-null  object        \n",
      " 2   started_at          84776 non-null  datetime64[ns]\n",
      " 3   ended_at            84776 non-null  datetime64[ns]\n",
      " 4   start_station_name  84776 non-null  object        \n",
      " 5   start_station_id    84776 non-null  int64         \n",
      " 6   end_station_name    84677 non-null  object        \n",
      " 7   end_station_id      84677 non-null  float64       \n",
      " 8   start_lat           84776 non-null  float64       \n",
      " 9   start_lng           84776 non-null  float64       \n",
      " 10  end_lat             84677 non-null  float64       \n",
      " 11  end_lng             84677 non-null  float64       \n",
      " 12  member_casual       84776 non-null  object        \n",
      "dtypes: datetime64[ns](2), float64(5), int64(1), object(5)\n",
      "memory usage: 8.4+ MB\n"
     ]
    }
   ],
   "source": [
    "fileN = workDir + '202004-divvy-tripdata.csv'\n",
    "td = pd.read_csv(fileN,parse_dates=[2,3])\n",
    "td.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/alp/Google Drive/Python/DataSets/Data_Divvy/202004-divvy-tripdata.json'"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileN[:-3]+'json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process2020(file,stations):\n",
    "    # this is easier: we need only read the file, convert the date-tmes into DT stamps\n",
    "    # since it's already saved as a month file, I don't need to mess about with the grouper either\n",
    "    # just  output it as a json file\n",
    "    trip_data = pd.read_csv(file,parse_dates=[2,3])\n",
    "\n",
    "    saveFile = file[:-3]+'json'\n",
    "    trip_data.to_json(saveFile,orient='index')\n",
    "    print(saveFile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alp/Google Drive/Python/DataSets/Data_Divvy/202101-divvy-tripdata.json\n",
      "/home/alp/Google Drive/Python/DataSets/Data_Divvy/202102-divvy-tripdata.json\n",
      "/home/alp/Google Drive/Python/DataSets/Data_Divvy/202103-divvy-tripdata.json\n",
      "/home/alp/Google Drive/Python/DataSets/Data_Divvy/202104-divvy-tripdata.json\n",
      "/home/alp/Google Drive/Python/DataSets/Data_Divvy/202105-divvy-tripdata.json\n",
      "/home/alp/Google Drive/Python/DataSets/Data_Divvy/202106-divvy-tripdata.json\n",
      "/home/alp/Google Drive/Python/DataSets/Data_Divvy/202107-divvy-tripdata.json\n",
      "/home/alp/Google Drive/Python/DataSets/Data_Divvy/202108-divvy-tripdata.json\n",
      "/home/alp/Google Drive/Python/DataSets/Data_Divvy/202109-divvy-tripdata.json\n",
      "/home/alp/Google Drive/Python/DataSets/Data_Divvy/202110-divvy-tripdata.json\n",
      "/home/alp/Google Drive/Python/DataSets/Data_Divvy/202111-divvy-tripdata.json\n",
      "/home/alp/Google Drive/Python/DataSets/Data_Divvy/202112-divvy-tripdata.json\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "file_names = sorted(glob.glob(workDir+'2021*.csv'))\n",
    "\n",
    "for file in file_names:\n",
    "    process2020(file,stations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
